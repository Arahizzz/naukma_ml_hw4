{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d99ad6b187596e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"../input/train.csv\",\n",
    "    usecols=[\n",
    "        \"id\",\n",
    "        \"comment_text\",\n",
    "        \"toxic\",\n",
    "        \"severe_toxic\",\n",
    "        \"obscene\",\n",
    "        \"threat\",\n",
    "        \"insult\",\n",
    "        \"identity_hate\",\n",
    "    ],\n",
    ")\n",
    "test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"id\", \"comment_text\"])\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "columns_base = [\"ID\", \"Comment_Text\"]\n",
    "columns_type = [\n",
    "    \"Is_Toxic\",\n",
    "    \"Is_Severe_Toxic\",\n",
    "    \"Is_Obscene\",\n",
    "    \"Is_Threat\",\n",
    "    \"Is_Insult\",\n",
    "    \"Is_Identity_Hate\",\n",
    "]\n",
    "columns_all = columns_base + columns_type\n",
    "train_df.columns = columns_all\n",
    "test_df.columns = columns_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86dfd5708ffa2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "LOGISTIC_REGRESSION = \"LogisticRegression\"\n",
    "RANDOM_FORREST = \"RandomForrest\"\n",
    "MODEL = LOGISTIC_REGRESSION\n",
    "NUM_OF_ROWS = 10_000\n",
    "RANDOM_SAMPLE = False\n",
    "USE_TEST_DATASET = False\n",
    "RUN_FULL_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50251314266182e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa34835b69adf34",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ccc222539bd37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_count = train_df[columns_type].sum()\n",
    "total_samples = len(train_df)\n",
    "type_percentage = (type_count / total_samples) * 100\n",
    "print(\"Size of train dataset:\")\n",
    "print(train_df.shape)\n",
    "\n",
    "rows_with_all_zeros = train_df[(train_df[columns_type] == 0).all(axis=1)]\n",
    "print(\"\\nCount of rows with all 0 types:\", len(rows_with_all_zeros))\n",
    "\n",
    "percentage_nonzero_types = 1 - (len(rows_with_all_zeros) / len(train_df))\n",
    "print(\n",
    "    \"\\nPercentage of rows with at least one non-zero type: {:.2%}\".format(\n",
    "        percentage_nonzero_types\n",
    "    )\n",
    ")\n",
    "\n",
    "class_summary = pd.DataFrame({\"Count\": type_count, \"Percentage\": type_percentage})\n",
    "class_summary[\"Percentage\"] = class_summary[\"Percentage\"].map(\"{:.2f}%\".format)\n",
    "print(\"\\nSum for each type with added value, percentage and labels:\")\n",
    "print(class_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97cd7e651ac749",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_category = pd.DataFrame(\n",
    "    {\n",
    "        \"Category\": [\"Good Comments\", \"Bad Comments\"],\n",
    "        \"Count\": [len(rows_with_all_zeros), len(train_df) - len(rows_with_all_zeros)],\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    comments_category[\"Count\"],\n",
    "    labels=comments_category[\"Category\"],\n",
    "    autopct=\"%1.2f%%\",\n",
    "    startangle=140,\n",
    ")\n",
    "plt.title(\"Distribution of Good and Bad Comments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d144a383060d3a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_rows_df = pd.DataFrame(columns=columns_all)\n",
    "type_counts = {}\n",
    "for text_type in columns_type:\n",
    "    mask = (train_df[text_type] == 1) & (train_df[columns_type].sum(axis=1) == 1)\n",
    "    count = mask.sum()\n",
    "    type_counts[text_type] = count\n",
    "    first_appearance = train_df[mask].head(1)\n",
    "    selected_rows_df = pd.concat(\n",
    "        [selected_rows_df, first_appearance], ignore_index=True\n",
    "    )\n",
    "\n",
    "print(\"Count of comments where only a specific type has 1 and others are 0:\")\n",
    "for text_type, count in type_counts.items():\n",
    "    print(f\"{text_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e873a1c7b157735",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_rows_df = pd.DataFrame(columns=columns_all)\n",
    "for text_type in columns_type:\n",
    "    mask = (train_df[text_type] == 1) & (train_df[columns_type].sum(axis=1) == 1)\n",
    "    first_appearance = train_df[mask].head(1)\n",
    "    selected_rows_df = pd.concat(\n",
    "        [selected_rows_df, first_appearance], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e2024d0c593c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(selected_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07128f652e505b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_stats = train_df.copy()\n",
    "\n",
    "# Calculate and display number of words, characters, symbols, and capital letters separately for the original comment text\n",
    "columns_stats = [\"num_words\", \"num_chars\", \"num_symbols\", \"num_capital_letters\"]\n",
    "sample_stats[\"num_words\"] = sample_stats[\"Comment_Text\"].apply(\n",
    "    lambda x: len(str(x).split())\n",
    ")\n",
    "sample_stats[\"num_chars\"] = sample_stats[\"Comment_Text\"].apply(len)\n",
    "sample_stats[\"num_symbols\"] = sample_stats[\"Comment_Text\"].apply(\n",
    "    lambda x: len(\n",
    "        [char for char in str(x) if not char.isalnum() and not char.isspace()]\n",
    "    )\n",
    ")\n",
    "sample_stats[\"num_capital_letters\"] = sample_stats[\"Comment_Text\"].apply(\n",
    "    lambda x: sum(1 for char in str(x) if char.isupper())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de53ec57bea5df1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_stats(columns_name):\n",
    "    mean = np.mean(sample_stats[columns_name])\n",
    "    median = np.median(sample_stats[columns_name])\n",
    "    std_dev = np.std(sample_stats[columns_name])\n",
    "    min_value = np.min(sample_stats[columns_name])\n",
    "    max_value = np.max(sample_stats[columns_name])\n",
    "\n",
    "    print(\"Mean:\", mean)\n",
    "    print(\"Median:\", median)\n",
    "    print(\"Standard Deviation:\", std_dev)\n",
    "    print(\"Minimum Value:\", min_value)\n",
    "    print(\"Maximum Value:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5406322463bd16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and display a histogram for the number of words\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(\n",
    "    sample_stats[\"num_words\"],\n",
    "    bins=range(min(sample_stats[\"num_words\"]), max(sample_stats[\"num_words\"]) + 1),\n",
    "    edgecolor=\"black\",\n",
    "    color=\"skyblue\",\n",
    "    lw=0,\n",
    ")\n",
    "plt.title(\"Histogram of Number of Words\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "print(\"Number of Words stats:\\n\")\n",
    "show_stats(\"num_words\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbb6fc282b0be8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and display a histogram for the number of characters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(\n",
    "    sample_stats[\"num_chars\"],\n",
    "    bins=range(min(sample_stats[\"num_chars\"]), max(sample_stats[\"num_chars\"]) + 1),\n",
    "    edgecolor=\"black\",\n",
    "    color=\"skyblue\",\n",
    "    lw=0,\n",
    ")\n",
    "plt.title(\"Histogram of Number of Characters\")\n",
    "plt.xlabel(\"Number of Characters\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "print(\"Number of Characters stats:\\n\")\n",
    "show_stats(\"num_chars\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e35cbde8b5849",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and display a histogram for the number of symbols\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 12))\n",
    "\n",
    "# Plot 1: Normal view\n",
    "axes[0].hist(\n",
    "    sample_stats[\"num_symbols\"],\n",
    "    bins=range(min(sample_stats[\"num_symbols\"]), max(sample_stats[\"num_symbols\"]) + 1),\n",
    "    color=\"purple\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[0].set_title(\"Histogram of Number of Symbols (Normal View)\")\n",
    "axes[0].set_xlabel(\"Number of Symbols\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot 2: Zoomed-in x-axis\n",
    "axes[1].hist(\n",
    "    sample_stats[\"num_symbols\"],\n",
    "    bins=range(min(sample_stats[\"num_symbols\"]), max(sample_stats[\"num_symbols\"]) + 1),\n",
    "    color=\"purple\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1].set_title(\"Histogram of Number of Symbols (Zoomed View)\")\n",
    "axes[1].set_xlabel(\"Number of Symbols\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].set_xlim(left=0, right=250)\n",
    "\n",
    "print(\"Number of Symbols stats:\\n\")\n",
    "show_stats(\"num_symbols\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc52d692a2e751f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and display a histogram for the number of capital letters\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 12))\n",
    "\n",
    "# Plot 1: Normal view\n",
    "axes[0].hist(\n",
    "    sample_stats[\"num_capital_letters\"],\n",
    "    bins=range(min(sample_stats[\"num_symbols\"]), max(sample_stats[\"num_symbols\"]) + 1),\n",
    "    color=\"purple\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[0].set_title(\"Histogram of Number of Capital Letters (Normal View)\")\n",
    "axes[0].set_xlabel(\"Number of Capital Letters\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot 2: Zoomed-in x-axis\n",
    "axes[1].hist(\n",
    "    sample_stats[\"num_capital_letters\"],\n",
    "    bins=range(min(sample_stats[\"num_symbols\"]), max(sample_stats[\"num_symbols\"]) + 1),\n",
    "    color=\"purple\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1].set_title(\"Histogram of Number of Capital Letters (Zoomed View)\")\n",
    "axes[1].set_xlabel(\"Number of Capital Letters\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].set_xlim(left=0, right=250)\n",
    "\n",
    "print(\"Number of Capital Letters stats:\\n\")\n",
    "show_stats(\"num_capital_letters\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef191339e400f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_matrix = sample_stats[columns_type + columns_stats].corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80d5845df61dff",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_stats.sort_values(by=\"num_capital_letters\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7cd6dd8ebdb5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_stats.sort_values(by=\"num_symbols\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edffc857ab025bec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ee49df04fef9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c95132e3d55db4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter all hate comments for model training\n",
    "hate_comments_df = (\n",
    "    train_df[train_df[columns_type].any(axis=1)].copy().reset_index(drop=True)\n",
    ")\n",
    "print(f\"Hate comments size: {len(hate_comments_df)}\")\n",
    "\n",
    "# Filter the same amount (or x2) of good comments for model training\n",
    "good_comments_df = (\n",
    "    train_df[train_df[columns_type].eq(0).all(axis=1)]\n",
    "    .sample(n=3 * len(hate_comments_df), random_state=42)\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Good comments size: {len(good_comments_df)}\")\n",
    "\n",
    "# Concatenate 50% hate and 50% good comments and shuffle\n",
    "train_df_copy = (\n",
    "    pd.concat([hate_comments_df, good_comments_df], ignore_index=True)\n",
    "    .sample(frac=1, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Final dataset size: {train_df_copy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079e17b75eb58bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.preprocessing import do_preprocessing\n",
    "\n",
    "train_df_copy[\"Comment_Text_Preprocessed\"] = train_df_copy[\"Comment_Text\"].apply(\n",
    "    lambda d: \" \".join(do_preprocessing(d))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1965d9b3b0fbc7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_df_copy[\"Comment_Text_Preprocessed\"]\n",
    "y = train_df_copy[columns_type]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5_000, max_df=0.9, smooth_idf=True, use_idf=True\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(X)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64ea74ff7ad998",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save tfidf_vectorizer\n",
    "joblib.dump(tfidf_vectorizer, \"./models/tfidf_vectorizer.joblib\")\n",
    "\n",
    "# Load tfidf_vectorizer\n",
    "# tfidf_vectorizer = joblib.load('./models/tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1bd0790ef081e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_copy_tfidf = pd.concat([train_df_copy, tfidf_df], axis=1)\n",
    "print(train_df_copy.shape)\n",
    "print(train_df_copy_tfidf.shape)\n",
    "print(f\"Unique words count: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c3f478c4d8b69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the top 100 most popular words\n",
    "top_100_words = tfidf_df.sum().sort_values(ascending=False).head(100)\n",
    "print(top_100_words.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516c1a506468b72",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for any non numeric values in the features dataframe\n",
    "tfidf_features = train_df_copy_tfidf[feature_names]\n",
    "numeric_df = tfidf_features.apply(pd.to_numeric, errors=\"coerce\")\n",
    "nan_values = numeric_df.isna().sum().sum()\n",
    "\n",
    "if nan_values == 0:\n",
    "    print(\"All values in the DataFrame are numeric.\")\n",
    "else:\n",
    "    print(f\"There are {nan_values} non-numeric values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4baa232b08526",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b361ca4776b43e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 2\n",
    "pca_2 = PCA(n_components=n_components)\n",
    "pca_result_2 = pca_2.fit_transform(tfidf_features)\n",
    "pca_result_df_2 = pd.DataFrame(\n",
    "    data=pca_result_2, columns=[f\"PCA_{i + 1}\" for i in range(n_components)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb432a474c1df9f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result_2[:, 0], pca_result_2[:, 1], alpha=0.5)\n",
    "plt.title(\"2D Scatter Plot of PCA Components\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55304f80e6e1815",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pca_2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcec2e1a3dc8f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "pca_3 = PCA(n_components=n_components)\n",
    "pca_result_3 = pca_3.fit_transform(tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4887f5650a53bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(\n",
    "    pca_result_3[:, 0],\n",
    "    pca_result_3[:, 1],\n",
    "    pca_result_3[:, 2],\n",
    "    c=\"blue\",\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "ax.set_xlabel(\"Principal Component 1\")\n",
    "ax.set_ylabel(\"Principal Component 2\")\n",
    "ax.set_zlabel(\"Principal Component 3\")\n",
    "ax.set_title(\"3D PCA Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4bcdcc7a0e1b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pca_3.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e054de96e8040",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate PCA with 0.95 explained variance\n",
    "# pca = PCA(0.95)\n",
    "# pca_result = pca.fit_transform(tfidf_features)\n",
    "# exp_var_pca = pca.explained_variance_ratio_\n",
    "# cum_sum_eigenvalues = np.cumsum(exp_var_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362e5893cf7cf07",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.bar(range(0, len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "# plt.step(range(0, len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid', label='Cumulative explained variance')\n",
    "# plt.ylabel('Explained variance ratio')\n",
    "# plt.xlabel('Principal component index')\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "#\n",
    "# print(f\"Number of components for 0.95 explained variance: {len(cum_sum_eigenvalues)}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cbe73ef868f9a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3a5088163f159",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "# Apply KMeans on UMAP data\n",
    "kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans_pca_labels = kmeans_pca.fit_predict(pca_result_2)\n",
    "labels = kmeans_pca_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c598cb02ea516c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the clustering results\n",
    "scatter = plt.scatter(\n",
    "    pca_result_2[:, 0],\n",
    "    pca_result_2[:, 1],\n",
    "    c=kmeans_pca_labels,\n",
    "    cmap=\"viridis\",\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "plt.scatter(\n",
    "    kmeans_pca.cluster_centers_[:, 0],\n",
    "    kmeans_pca.cluster_centers_[:, 1],\n",
    "    s=200,\n",
    "    c=\"red\",\n",
    "    marker=\"X\",\n",
    "    label=\"Centroids\",\n",
    ")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.legend()\n",
    "\n",
    "unique_labels = set(labels)\n",
    "print(\"Number of clusters:\", len(unique_labels) - (1 if -1 in unique_labels else 0))\n",
    "for cluster_label in unique_labels:\n",
    "    if cluster_label == -1:\n",
    "        print(f\"Noise points: {sum(labels == cluster_label)}\")\n",
    "    else:\n",
    "        print(f\"Cluster {cluster_label}: {sum(labels == cluster_label)} points\")\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a3857b09f9c8e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737982fdb6c4c05",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5997d2509a4986",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d9d14fc03c0d5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e629ed5174659",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_labels = [\"Toxic\", \"Severe_Toxic\", \"Obscene\", \"Threat\", \"Insult\", \"Identity_Hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93ee2f718f4235",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a202d8e087fb050",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76aceaab8694e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    clf = MultiOutputClassifier(lr)\n",
    "    clf = clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf1ae0a89d156f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    # Save model\n",
    "    joblib.dump(clf, \"./models/logistic_regression_classifier_model.joblib\")\n",
    "    # Load model\n",
    "    # clf = joblib.load('./models/logistic_regression_classifier_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca079d6ee5065ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the class labels for each classifier\n",
    "# for i, estimator in enumerate(clf.estimators_):\n",
    "#     print(f\"Classifier {i + 1} Class Labels:\", estimator.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e1dc14ea21c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.663 - 0.078 x/x  10000 features\n",
    "# 0.762 - 0.056 x/2x 10000 features\n",
    "# 0.764 - 0.055 x/2x 5000 features\n",
    "# 0.815 - 0.043 x/3x 5000 features\n",
    "# 0.872 - 0.03  x/5x 5000 features\n",
    "# Evaluate the model\n",
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    hamming = round(hamming_loss(y_test, y_pred), 3)\n",
    "    classification_report_str = classification_report(y_test, y_pred, zero_division=1)\n",
    "    print(\"Accuracy Score: \", accuracy)\n",
    "    print(\"Hamming Loss: \", hamming)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a39f0939cfb687",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    sample_text = [\"some not very toxic toxic toxic text\"]\n",
    "    sample_text_tfidf = tfidf_vectorizer.transform(sample_text)\n",
    "    sample_text_pred_prob = clf.predict_proba(sample_text_tfidf)\n",
    "    prediction_df = pd.DataFrame()\n",
    "    for i, output_name in enumerate(class_labels):\n",
    "        prediction_df[output_name] = sample_text_pred_prob[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e7df47e244513",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    print(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594956b67a43b52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    base_classifier = RandomForestClassifier(random_state=42)\n",
    "    multi_output_classifier = MultiOutputClassifier(base_classifier)\n",
    "    multi_output_classifier = multi_output_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501ff45280a16e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    # Save model\n",
    "    joblib.dump(\n",
    "        multi_output_classifier, \"./models/random_forrest_classifier_model.joblib\"\n",
    "    )\n",
    "    # Load model\n",
    "    # multi_output_classifier = joblib.load('./models/random_forrest_classifier_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3488eafaf8d1e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "if MODEL == RANDOM_FORREST:\n",
    "    y_pred = multi_output_classifier.predict(X_test_tfidf)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    hamming = round(hamming_loss(y_test, y_pred), 3)\n",
    "    classification_report_str = classification_report(y_test, y_pred, zero_division=1)\n",
    "    print(\"Accuracy Score: \", accuracy)\n",
    "    print(\"Hamming Loss: \", hamming)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533d5112355e4bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    prediction_probabilities = multi_output_classifier.predict_proba(X_test_tfidf)\n",
    "    prediction_df = pd.DataFrame()\n",
    "    for i, output_name in enumerate(class_labels):\n",
    "        prediction_df[output_name] = prediction_probabilities[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40ee47e4d2977b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60870f2374ea143d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    sample_text = [\"some toxic text\"]\n",
    "    sample_text_tfidf = tfidf_vectorizer.transform(sample_text)\n",
    "    sample_text_pred_prob = multi_output_classifier.predict_proba(sample_text_tfidf)\n",
    "    prediction_df = pd.DataFrame()\n",
    "    for i, output_name in enumerate(class_labels):\n",
    "        prediction_df[output_name] = sample_text_pred_prob[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fa1c982bf45c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    print(prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961a0ea29578590",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889aa39a7d6a7224",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_submission = [\n",
    "    \"id\",\n",
    "    \"toxic\",\n",
    "    \"severe_toxic\",\n",
    "    \"obscene\",\n",
    "    \"threat\",\n",
    "    \"insult\",\n",
    "    \"identity_hate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb98ac1c903795",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e5ee06b67fc4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good comment\n",
    "test_df.loc[test_df[\"ID\"] == \"00177176f33f587e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921425fbca92ec9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bad comment\n",
    "test_df.loc[test_df[\"ID\"] == \"0013fed3aeae76b7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4e458bc837d4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_text_tfidf = tfidf_vectorizer.transform(test_df[\"Comment_Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50736bf3dbbed899",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    test_text_tfidf_prob = clf.predict_proba(test_text_tfidf)\n",
    "    prediction_df = pd.DataFrame()\n",
    "    for i, output_name in enumerate(class_labels):\n",
    "        prediction_df[output_name] = test_text_tfidf_prob[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67096e7fadab16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == LOGISTIC_REGRESSION:\n",
    "    result_df = pd.concat([test_df[\"ID\"], prediction_df], axis=1)\n",
    "    result_df.columns = columns_submission\n",
    "    result_df.to_csv(\"../output/submission.csv\", index=False)\n",
    "    result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24659563bc8ca946",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    test_text_tfidf_prob = multi_output_classifier.predict_proba(test_text_tfidf)\n",
    "    prediction_df = pd.DataFrame()\n",
    "    for i, output_name in enumerate(class_labels):\n",
    "        prediction_df[output_name] = test_text_tfidf_prob[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d3920b5216dce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == RANDOM_FORREST:\n",
    "    result_df = pd.concat([test_df[\"ID\"], prediction_df], axis=1)\n",
    "    result_df.columns = columns_submission\n",
    "    result_df.to_csv(\"../output/submission_random_forrest.csv\", index=False)\n",
    "    result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
