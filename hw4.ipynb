{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./input/train.csv', usecols=['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n",
    "test_df = pd.read_csv('./input/test.csv', usecols=['id', 'comment_text'])\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "columns_base = ['ID', 'Comment_Text']\n",
    "columns_type = ['Is_Toxic', 'Is_Severe_Toxic', 'Is_Obscene', 'Is_Threat', 'Is_Insult', 'Is_Identity_Hate']\n",
    "columns_all = columns_base + columns_type\n",
    "train_df.columns = columns_all\n",
    "test_df.columns = columns_base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58d99ad6b187596e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "NUM_OF_ROWS = 10_000\n",
    "RANDOM_SAMPLE = False\n",
    "USE_TEST_DATASET = False\n",
    "RUN_FULL_PCA = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b86dfd5708ffa2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d50251314266182e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aa34835b69adf34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type_count = train_df[columns_type].sum()\n",
    "total_samples = len(train_df)\n",
    "type_percentage = (type_count / total_samples) * 100\n",
    "print(\"Size of train dataset:\")\n",
    "print(train_df.shape)\n",
    "\n",
    "rows_with_all_zeros = train_df[(train_df[columns_type] == 0).all(axis=1)]\n",
    "print(\"\\nCount of rows with all 0 types:\", len(rows_with_all_zeros))\n",
    "\n",
    "percentage_nonzero_types = 1 - (len(rows_with_all_zeros) / len(train_df))\n",
    "print(\"\\nPercentage of rows with at least one non-zero type: {:.2%}\".format(percentage_nonzero_types))\n",
    "\n",
    "class_summary = pd.DataFrame({'Count': type_count, 'Percentage': type_percentage})\n",
    "class_summary['Percentage'] = class_summary['Percentage'].map('{:.2f}%'.format)\n",
    "print(\"\\nSum for each type with added value, percentage and labels:\")\n",
    "print(class_summary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e5ccc222539bd37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comments_category = pd.DataFrame({\n",
    "    'Category': ['Good Comments', 'Bad Comments'],\n",
    "    'Count': [len(rows_with_all_zeros), len(train_df) - len(rows_with_all_zeros)]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(comments_category['Count'], labels=comments_category['Category'], autopct='%1.2f%%', startangle=140)\n",
    "plt.title('Distribution of Good and Bad Comments')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d97cd7e651ac749"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_rows_df = pd.DataFrame(columns=columns_all)\n",
    "type_counts = {}\n",
    "for text_type in columns_type:\n",
    "    mask = (train_df[text_type] == 1) & (train_df[columns_type].sum(axis=1) == 1)\n",
    "    count = mask.sum()\n",
    "    type_counts[text_type] = count\n",
    "    first_appearance = train_df[mask].head(1)\n",
    "    selected_rows_df = pd.concat([selected_rows_df, first_appearance], ignore_index=True)\n",
    "\n",
    "print(\"Count of comments where only a specific type has 1 and others are 0:\")\n",
    "for text_type, count in type_counts.items():\n",
    "    print(f\"{text_type}: {count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82d144a383060d3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_rows_df = pd.DataFrame(columns=columns_all)\n",
    "for text_type in columns_type:\n",
    "    mask = (train_df[text_type] == 1) & (train_df[columns_type].sum(axis=1) == 1)\n",
    "    first_appearance = train_df[mask].head(1)\n",
    "    selected_rows_df = pd.concat([selected_rows_df, first_appearance], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e873a1c7b157735"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(selected_rows_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff8e2024d0c593c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a5ee49df04fef9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter all hate comments for model training\n",
    "hate_comments_df = train_df[train_df[columns_type].any(axis=1)].copy().reset_index(drop=True)\n",
    "\n",
    "# Filter the same amount of good comments for model training\n",
    "good_comments_df = train_df[train_df[columns_type].eq(0).all(axis=1)].sample(n=len(hate_comments_df),random_state=42).copy().reset_index(drop=True)\n",
    "\n",
    "# Concatenate 50% hate and 50% good comments and shuffle\n",
    "train_df_copy = pd.concat([hate_comments_df, good_comments_df], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56c95132e3d55db4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df_copy.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1d12cf7cb908cff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from preprocessing import do_preprocessing\n",
    "\n",
    "train_df_copy['Comment_Text_Preprocessed'] = train_df_copy[\"Comment_Text\"].apply(lambda d: \" \".join(do_preprocessing(d)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9079e17b75eb58bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = train_df_copy['Comment_Text_Preprocessed']\n",
    "y = train_df_copy[columns_type]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10_000, max_df=0.9, smooth_idf=True, use_idf=True)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(X)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df1965d9b3b0fbc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df_copy_tfidf = pd.concat([train_df_copy, tfidf_df], axis=1)\n",
    "print(train_df_copy.shape)\n",
    "print(train_df_copy_tfidf.shape)\n",
    "print(f\"Unique words count: {len(feature_names)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fef1bd0790ef081e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the top 100 most popular words\n",
    "top_100_words = tfidf_df.sum().sort_values(ascending=False).head(100)\n",
    "print(top_100_words.to_string())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2c3f478c4d8b69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for any non numeric values in the features dataframe\n",
    "tfidf_features = train_df_copy_tfidf[feature_names]\n",
    "numeric_df = tfidf_features.apply(pd.to_numeric, errors='coerce')\n",
    "nan_values = numeric_df.isna().sum().sum()\n",
    "\n",
    "if nan_values == 0:\n",
    "    print(\"All values in the DataFrame are numeric.\")\n",
    "else:\n",
    "    print(f\"There are {nan_values} non-numeric values in the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3516c1a506468b72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36b4baa232b08526"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 2\n",
    "pca_2 = PCA(n_components=n_components)\n",
    "pca_result_2 = pca_2.fit_transform(tfidf_features)\n",
    "pca_result_df_2 = pd.DataFrame(data=pca_result_2, columns=[f'PCA_{i + 1}' for i in range(n_components)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b361ca4776b43e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result_2[:, 0], pca_result_2[:, 1], alpha=0.5)\n",
    "plt.title('2D Scatter Plot of PCA Components')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beb432a474c1df9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pca_2.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d55304f80e6e1815"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "pca_3 = PCA(n_components=n_components)\n",
    "pca_result_3 = pca_3.fit_transform(tfidf_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2dcec2e1a3dc8f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_result_3[:, 0], pca_result_3[:, 1], pca_result_3[:, 2], c='blue', marker='o', edgecolors='k')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('3D PCA Plot')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f4887f5650a53bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pca_3.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe4bcdcc7a0e1b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate PCA with 0.95 explained variance\n",
    "# pca = PCA(0.95)\n",
    "# pca_result = pca.fit_transform(tfidf_features)\n",
    "# exp_var_pca = pca.explained_variance_ratio_\n",
    "# cum_sum_eigenvalues = np.cumsum(exp_var_pca)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c4e054de96e8040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.bar(range(0, len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "# plt.step(range(0, len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid', label='Cumulative explained variance')\n",
    "# plt.ylabel('Explained variance ratio')\n",
    "# plt.xlabel('Principal component index')\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# \n",
    "# print(f\"Number of components for 0.95 explained variance: {len(cum_sum_eigenvalues)}\")\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5362e5893cf7cf07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1cbe73ef868f9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 7\n",
    "\n",
    "# Apply KMeans on UMAP data\n",
    "kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans_pca_labels = kmeans_pca.fit_predict(pca_result_2)\n",
    "labels = kmeans_pca_labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6be3a5088163f159"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the clustering results\n",
    "scatter = plt.scatter(pca_result_2[:, 0], pca_result_2[:, 1], c=kmeans_pca_labels, cmap='viridis', marker='o', edgecolors='k')\n",
    "plt.scatter(kmeans_pca.cluster_centers_[:, 0], kmeans_pca.cluster_centers_[:, 1], s=200, c='red', marker='X',label='Centroids')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.legend()\n",
    "\n",
    "unique_labels = set(labels)\n",
    "print(\"Number of clusters:\", len(unique_labels) - (1 if -1 in unique_labels else 0))\n",
    "for cluster_label in unique_labels:\n",
    "    if cluster_label == -1:\n",
    "        print(f\"Noise points: {sum(labels == cluster_label)}\")\n",
    "    else:\n",
    "        print(f\"Cluster {cluster_label}: {sum(labels == cluster_label)} points\")\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55c598cb02ea516c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d3a3857b09f9c8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df5997d2509a4986"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd0d9d14fc03c0d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_labels = ['Toxic', 'Severe_Toxic', 'Obscene', 'Threat', 'Insult', 'Identity_Hate']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04e629ed5174659"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad93ee2f718f4235"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a202d8e087fb050"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = MultiOutputClassifier(lr)\n",
    "clf = clf.fit(X_train_tfidf, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e76aceaab8694e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the class labels for each classifier\n",
    "for i, estimator in enumerate(clf.estimators_):\n",
    "    print(f\"Classifier {i + 1} Class Labels:\", estimator.classes_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca079d6ee5065ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test_tfidf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b064e0ce0e047ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score: ', accuracy_score(y_test, prediction))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "133e1dc14ea21c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print('Hamming Loss: ', round(hamming_loss(y_test, prediction),2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35b4671eac22f76e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_text = [\"some toxic text\"]\n",
    "sample_text_tfidf = tfidf_vectorizer.transform(sample_text)\n",
    "sample_text_pred_prob = clf.predict_proba(sample_text_tfidf)\n",
    "prediction_df = pd.DataFrame()\n",
    "for i, output_name in enumerate(class_labels):\n",
    "    prediction_df[output_name] = sample_text_pred_prob[i][:, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a39f0939cfb687"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "553e7df47e244513"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "base_classifier = RandomForestClassifier(random_state=42)\n",
    "multi_output_classifier = MultiOutputClassifier(base_classifier)\n",
    "multi_output_classifier = multi_output_classifier.fit(X_train_tfidf, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6594956b67a43b52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = multi_output_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd947474e8e9a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction_probabilities = multi_output_classifier.predict_proba(X_test_tfidf)\n",
    "prediction_df = pd.DataFrame()\n",
    "for i, output_name in enumerate(class_labels):\n",
    "    prediction_df[output_name] = prediction_probabilities[i][:, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2533d5112355e4bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b40ee47e4d2977b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_text = [\"some toxic text\"]\n",
    "sample_text_tfidf = tfidf_vectorizer.transform(sample_text)\n",
    "sample_text_pred_prob = multi_output_classifier.predict_proba(sample_text_tfidf)\n",
    "prediction_df = pd.DataFrame()\n",
    "for i, output_name in enumerate(class_labels):\n",
    "    prediction_df[output_name] = sample_text_pred_prob[i][:, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60870f2374ea143d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e5fa1c982bf45c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5961a0ea29578590"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns_submission = ['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "889aa39a7d6a7224"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cacb98ac1c903795"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Good comment\n",
    "test_df.loc[test_df['ID'] == '00177176f33f587e']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db4e5ee06b67fc4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bad comment\n",
    "test_df.loc[test_df['ID'] == '0013fed3aeae76b7']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9921425fbca92ec9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_text_tfidf = tfidf_vectorizer.transform(test_df['Comment_Text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cb4e458bc837d4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_text_tfidf_prob = clf.predict_proba(test_text_tfidf)\n",
    "prediction_df = pd.DataFrame()\n",
    "for i, output_name in enumerate(class_labels):\n",
    "    prediction_df[output_name] = test_text_tfidf_prob[i][:, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50736bf3dbbed899"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = pd.concat([test_df['ID'], prediction_df], axis=1)\n",
    "result_df.columns = columns_submission\n",
    "result_df.to_csv('./output/submission.csv', index=False)\n",
    "result_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67096e7fadab16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_text_tfidf_prob = multi_output_classifier.predict_proba(test_text_tfidf)\n",
    "prediction_df = pd.DataFrame()\n",
    "for i, output_name in enumerate(class_labels):\n",
    "    prediction_df[output_name] = test_text_tfidf_prob[i][:, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24659563bc8ca946"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = pd.concat([test_df['ID'], prediction_df], axis=1)\n",
    "result_df.columns = columns_submission\n",
    "result_df.to_csv('./output/submission_random_forrest.csv', index=False)\n",
    "result_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "676d3920b5216dce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
